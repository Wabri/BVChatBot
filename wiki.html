= Prototype 3 (with [https://github.com/Wabri/ChatBotPayments Repository ChatBotPayments]) =

== Introduction ==
Questo progetto di tesi e tirocinio è stato fatto da Gabriele Puliti per il corso di laurea in informatica Università degli studi di Firenze presso E.D.P.Service. Il progetto si basa sulla creazione di un servizio di chat bot che permetta di effettuare pagamenti. Lo sviluppo del prototipo è diviso in 2 parti: frontend e backend.

== Frontend ==

Questa parte è suddivisa in 3 file: chatbot.html, chatbotController.js, chatbotUtilityService.js. Nel primo file ci sono definiti sono 2 zone di testo che rappresentano il botta e risposta utente-bot e un form che serve per inviare il messaggio al bot con all'interno un bottone per inviare il codice e un altro per il microfono che permette di parlare. Nel controller ci sono le funzioni usate dai due pulsanti all'interno del form definito nel file precendente con annesse funzioni di servizio come voiceSynth e voiceRecognition, la prima permette di generare un audio con la risposta del bot mentre la seconda permette di transcrivere la frase pronunciata dall'utente in testo. Nel terzo script ci sono alcune funzioni necessarie per il controller come sendMessageToRasa e receiveMessageFromRasa necessarie al controller per inviare e ricevere i messaggi da Rasa.

=== Codice chatbot.html ===

<pre>
  <!DOCTYPE html>

<html>

<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
	<meta name="chatbot" content="width=device-width">

	<title>Prototype of ChatBot</title>

</head>

<body>
	<section>
		<h1>BVChatBot</h1>

		</br>
		Te: {{userMessage}}
		</br>
		Bot: {{botMessage}}
		<span ng-model="botMessage" id="botMessage"> </span>

		<form id="messageForm">
			<input ng-model="inputMessage" id="inputMessage" autocomplete="off" />
			<button ng-click="sendUserMessage()" id="write">Send</button>
			<button ng-click="listenUserMessage()" id="talk">Talk</button>
		</form>

	</section>
</body>

</html>

</pre>

=== Codice chatbotController.js ===

<pre>
  (function() {
  'use strict';

  angular.module('revux').controller('ChatbotCtrl', ChatbotCtrl);

  function ChatbotCtrl($http, $scope, $cookies, ChatbotService) {

    $scope.userMessage = "Il tuo messaggio";
    $scope.botMessage = "Il messaggio del bot";

    var xsrfToken = $cookies.get($http.defaults.xsrfCookieName);

    var id = ChatbotService.makeID();

    ChatbotService.enstablishConnectionWithRasa(xsrfToken, id);

    $scope.inputMessage = "Manda un messaggio al bot!";

    $scope.sendUserMessage = sendUserMessage;

    function voiceSynth (text) {
    	var utterance = new SpeechSynthesisUtterance();
    	utterance.lang = "it-IT";
    	utterance.text = text;
    	speechSynthesis.speak(utterance);
    }
    
    function voiceRecognition() {
    	var recognizer = new speechRecognition();
    	recognizer.continous = false; // questo serve per stoppare il riconoscimento quando l'utente smette di parlare
    	recognizer.lang = "it-IT";
    	
    	recognizer.onresult = function(event) {
    		return event.results[0][0].transcript;
    	}
    }
    
    function sendUserMessage() {

      ChatbotService.sendMessageToRasa(id, $scope.inputMessage).then(function(response) {
        $scope.userMessage = $scope.inputMessage;
        $scope.inputMessage = "";
        ChatbotService.reciveMessageFromRasa(id,$scope.inputMessage).then(function(response) {
            if (response.data[0].text != null) {
            	$scope.botMessage = response.data[0].text;
            	voiceSynth($scope.botMessage);
            } else {
            	$scope.botMessage = "Errore";
            }
        }, function() {});
      }, function() {});
      
    }
    
    function listenUserMessage() {
//    	annyang.addCommands(commands);
//    	annyang.debug();
//    	annyang.start();
    	
    	$scope.botMessage = voiceRecognition();
    	
    	ChatbotService.sendMessageToRasa(id, $scope.inputMessage).then(function(response) {
            $scope.userMessage = $scope.inputMessage;
            $scope.inputMessage = "";
            ChatbotService.reciveMessageFromRasa(id,$scope.inputMessage).then(function(response) {
                if (response.data[0].text != null) {
                	$scope.botMessage = response.data[0].text;
                	voiceSynth($scope.botMessage);
                } else {
                	$scope.botMessage = "Errore";
                }
            }, function() {});
          }, function() {});
    	
    }
    
//    usato da annyang prima di scoprire che c'era il riconoscimento vocale integrato 
//    var commands = {
//    		'*message' : function(message) {
//    			console.log(message);
//    			$scope.userMessage = message;
//    			ChatbotService.sendMessageToRasa(id, $scope.userMessage).then(function(response) {
//    		        ChatbotService.reciveMessageFromRasa(id, $scope.userMessage).then(function(response) {
//    		            if (response.data[0].text != null) {
//    		            	$scope.botMessage = response.data[0].text;
//    		            	voiceSynth($scope.botMessage);
//    		            } else {
//    		            	$scope.botMessage = "Errore";
//    		            }
//    		        }, function() {});
//    		      }, function() {});
//    		}
//    }

  }

})();

</pre>

=== Codice chatbotUtilityService.js ===

<pre>
  (function() {
  'use strict';

  angular.module('revux').service("ChatbotService", ChatbotService);

  function ChatbotService($http) {

    var self = this;
    self.enstablishConnectionWithRasa = enstablishConnectionWithRasa;
    self.makeID = makeID;

    function enstablishConnectionWithRasa(xsrfToken, id) {
      $http.post("http://192.168.11.24:5005/conversations/" + id + "/tracker/events?token=wabridev",
        [{"event": "slot",
        "name": "xsrftoken",
        "value": xsrfToken }
      ],
      {
        'withCredentials': false
      }).then(function(response) {
        console.log("token salvato correttamente", response);
      }, function() {
        console.log("token impossibile da salvare");
      });
    }

    function makeID() {
      var text = "";
      var possible = "ABCDEFGHIJKLMNOPRSTUVWXYZabcdefghijklmnopqrstuvwxyz1234567890";
      for (var i = 0; i < 29; i++) {
        text += possible.charAt(Math.floor(Math.random() * possible.length));
      }
      return text;
    }

    function sendMessageToRasa(id, message) {
    	return $http.post("http://192.168.11.24:5005/conversations/" + id + "/parse?token=wabridev", {
            "query": message
        }, {
          'withCredentials': false
        });
    }
    
    function reciveMessageFromRasa(id,message) {
    	return $http.post("http://192.168.11.24:5005/conversations/" + id + "/respond?token=wabridev", {
          "query":message
        }, {
          'withCredentials': false
        });
    }

  }
})();

</pre>

== Backend Rasa ==

Inizialmente questa parte veniva fatta da [https://dialogflow.com/ Dialogflow] strumento di casa google che permette di creare con un'interfaccia molto semplice un bot personalizzato. Per una questione di riservatezza dei dati sensibili è stato richiesto di cambiare strumento per costruire l'intelligenza artificiale. Dopo varie ricerche ho deciso di usare [https://rasa.com/ Rasa], open source che ha le stesse funzioni di dialogflow ma con una fase di configurazione e programmazione delle azioni più complessa. Rasa propone 2 funzionalità: Natural Language Understanding e Core.

=== NLU ===

Un'intelligenza artificiale NLU (abbreviazione di natural language understanding) prende in input un testo e restituisce in output diverse informazioni: l'intento della frase (i cosidetti intents) e le parole chiave che è possibile estrapolare (chiamate entities). Prima di essere in grado di fare un riconoscimento vero e proprio è necessario allenare l'intelligenza con degli esempi. La creazione di questi dati viene fatta tramite dei file json:
<pre>
{
  "rasa_nlu_data": {
    "regex_features": [],
    "entity_synonyms": [],
    "common_examples": []
  }
}
</pre>
Sono molto semplici da comprendere: regex_features sono le espressioni regolari, entity_synonyms sono i sinonimi che è possibile incontrare, common_examples sono gli esempi che è necessario fornire per allenare l'intelligenza. Gli esempi che ho scritto io si trovano nella Repository Github [https://github.com/Wabri/ChatBotPayments/tree/master/RASA_IA/data/intents ChatBotPayments] suddivisi per tipo di intento. Potevo estrarre i dati generati con dialogflow, ma ho preferito riscriverli per non dipendere da uno strumento esterno in modo da rendere più facile da mantenere. Prima di allenare l'intelligenza è necessario creare il file di configurazione in cui indichiamo la lingua e lo strumento usato per fare training, ho quindi creato il file nluModelConfig che si trova [https://github.com/Wabri/ChatBotPayments/tree/master/RASA_IA/nluModelConfig.yml NLU Config] che ha questo contenuto:
<pre>
language: "it"

pipeline: "spacy_sklearn"
</pre>
A questo punto è possibile eseguire il training che genererà un modello dell'intelligenza artificiale.

=== CORE ===

Questa è la parte fondamentale del progetto, il CORE è quello che effettivamente fa tutto il lavoro: esegue nlu, elabora una risposta e tiene traccia della conversazione. Per maggiori informazioni è possibile leggere il tutorial che ho scritto [https://github.com/Wabri/LearningRasa#rasacore Learning Rasa Core] oppure direttamente nei docs ufficiali [http://www.rasa.com/docs/core/quickstart/ Rasa Docs]. Per poter eseguire il server Rasa con tutte le funzionalità che vogliamo è necessario allenarlo a rispondere alle domande che gli poniamo, perchè con il solo NLU sa solo capire quello che gli diciamo ma non sa come elaborare una risposta. Il CORE è suddiviso in 3 parti: domain, stories e actions. Il DOMAIN è il dominio di interesse dell'intelligenza artificiale, questo viene configurato con un file scritto in Yaml in cui viengono definiti: intents e entities da tracciare e riconoscere (definiti precedentemente dal NLU), gli slots sono contenitori di informazioni che vengono (o possono) essere usati durante la conversazione per salvare dati, actions sono le azioni che il bot può eseguire per rispondere a una certa frase in input, templates sono azioni di default che possono essere usate durante una conversazione. Il domain di questo progetto è [https://github.com/Wabri/ChatBotPayments/tree/master/RASA_IA/payment_domain.yml Rasa CORE Domain], è possibile notare che le voci entities e templates non sono definite perchè non necessarie. Le ACTIONS sono definite in uno script in python chiamato [https://github.com/Wabri/ChatBotPayments/tree/master/RASA_IA/action.py actions.py] dove sono implementate le risposte del bot, questo script è dove viene effettivamente completato il pagamento. Precisamente è definito dalla riga 73 alla 116 in cui si trova la classe ActionPaymentConfermation che è una delle azioni del bot. Ultima parte ma non meno importante sono le cosìdette STORIES in cui vengono ricreate alcune conversazioni tipo dalla più semplice a quella più complessa, queste poi verranno usate dal training del modello che verrà poi usato dal server per rispondere. Un esempio molto semplice è:
<pre>
Utente: "Ciao bot"
Bot: "Salve"
Utente: "Arrivederci"
Bot: "Alla prossima"
</pre>
Per far comprendere questo esempio all'intelligenza artificiale è necessario ricreare questa conversazione in un file di configurazione Markdown di questo tipo:
<pre>
# storia 1
* inizio_conversazione
    - risposta_inizio_conversazione
* fine_conversazione
    - risposta_fine_conversazione
</pre>
La prima riga rappresenta una descrizione della storia (non ha un riscontro effettivo sul training è solo utile a livello di sviluppo per differenziare le varie storie che vengono scritte), le righe successive sono divise in 2 simboli: con simbolo * viene indicato l'intento della frase proveniente dell'utente, mentre con il simbolo - viene definita l'azione che il bot deve eseguire come risposta. Le stories che ho generato per questo bot è possibile vederle in questo file [https://github.com/Wabri/ChatBotPayments/tree/master/RASA_IA/stories/payment_stories.md Stories]. A questo punto viene fatto il training dando in input questi 3 file: domain, actions, stories che a sua volta come il NLU genererà un modello di intelligenza artificiale che riesce a tenere una conversazione con un utente.

== Requisiti ==

Per le dipendenze Python ho creato grazie all'uso di un virtual environment un [https://github.com/Wabri/ChatBotPayments/tree/master/RASA_IA/requirements.txt requirements.txt] generato da pip (gestore dei packages di python) dove sono stilate tutte le dipendenze necessarie per eseguire il progetto. Per installare tramite questo file basterà eseguire nella cartella RASA_IA il comando:
<pre>
pip install -r requirements.txt
</pre>
Ho cercato di automatizzare il processo di installazione, training e run del server usando uno script in bash che è possibile trovare dentro la cartella RASA_IA con il nome di [https://github.com/Wabri/ChatBotPayments/tree/master/RASA_IA/loadAndRun.sh loadAndRun.sh]. Le istruzioni all'interno di questo file sono le seguenti:
<pre>
pip install -r requirements.txt

spacy download it_core_news_sm

spacy link it_core_news_sm it --force

python -m rasa_nlu.train --config nluModelConfig.yml --data data/ --project current --fixed_model_name nlu --path models/

python -m rasa_core.train -d payment_domain.yml -s stories/payment_stories.md -o models/current/core --epochs 300

python -m rasa_core.server -d models/current/core -u models/current/nlu -o out.log --cors 'http://192.168.13.15:9001' --verbose --auth_token wabridev
</pre>
Il primo comando è già stato spiegato. Il secondo comando è un comando spacy (libreria python che viene usata dal NLU nella pipeline definita nelle config [https://github.com/Wabri/ChatBotPayments/tree/master/RASA_IA/nluModelConfig.yml NluModelConfig]), il suo scopo è scaricare il dizionario che verrà usato dall'intelligenza artificiale (nel nostro caso l'italiano). Per un qualsiasi altro dizionario è possibile vedere i modelli che sono messi a disposizione nella pagina web ufficiale
[https://spacy.io/models/ spacy.io]. Il terzo comando è un comando molto importante che genera un soft link tra il dizionario e l'uso stesso del dizionario all'interno del codice spacy. Gli ultimi 3 comandi riguardano Rasa:
<ol>
<li> Training del NLU </li>
<li> Training del Core </li>
<li> Run del server </li>
</ol>

== Logica di funzionamento ==

Ci sono 3 componenti fondamentali che permettono il funzionamento di tutto questo: Rasa Server, Spring Server e Revux.
Il server Rasa è necessario eseguirlo in un server linux con python2.7, per provare l'effettivo funzionamento basterà accedere alla pagina ip_server:5005 (che attualmente dovrebbe essere 192.168.11.24:5005) e dovremmo avere una pagina html con scritto:
<pre>
  hello from Rasa Core: 0.10.4
</pre>
Se il risultato è questo dovremmo poter accedere a tutti i suoi servizi, a meno che non ci siano errori vari o problemi di cors in quel caso è necessario reimpostare il bash loadAndRun.sh modificando il campo cors con l'origin giusto.

Una volta lanciato il server spring e revux sarà possibile eseguire il login e conseguentemente accedere alla chat. La prima cosa che viene fatta dal controller è generare un id unico per la conversazione, lo creo tramite il metodo makeID all'interno del chatbotUtilityService, ogni utente quindi avrà il suo identificativo specifico. Il passo successivo è quello di mandare il xsrfToken a rasa tramite una post, questo permetterà a rasa di storare all'interno dello slot 'xsrfToken' della conversation questo token necessario per la richiesta di pagamento perchè fa parte del cookie insieme al jsession. Dovrebbe inviare insieme a questo anche il jsession, ma ancora non ho trovato il modo di farlo infatti il primo punto del TODO è proprio questo.  Nella chat c'è un riferimento al pulsante del microfono (non ancora implementato durante l'integrazione, vedi TODO in fondo alla pagina), due campi che rappresentano il testo dell'utente e la risposta del bot, infine una zona di inserimento testo dove ci sta la frase che l'utente invia al bot. Quando viene scritto un messaggio all'interno di quella zona di testo il controller tramite una post invia la richiesta a rasa e subito dopo richiede la risposta. Quindi il botta e risposta tra utente e bot si completa in 2 passi:
<ol>

<li> Invio richiesta di parsing del testo tramite la post:
<pre>
$http.post("http://192.168.11.24:5005/conversations/" + id + "/parse?token=wabridev", {
        "query": vm.inputMessage
    }, {
      'withCredentials': false
});
</pre>
</li>

<li> Invio della risposta da dare all'utente:
<pre>
$http.post("http://192.168.11.24:5005/conversations/" + id + "/respond?token=wabridev", {
      "query": $scope.userMessage
    }, {
      'withCredentials': false
});
</pre>
</li>

</ol>
Con conseguente modifica dei vari campi.
Il bot riuscirà a comprendere l'intento della frase solo nei casi di: saluto, richiesta di pagamento, conferma del pagamento, rifiuto del pagamento, ringraziamento. Considerando il fatto che non ho creato un data set corposo per i training, l'intelligenza è possibile che ogni tanto non riesca a comprendere quello che stiamo cercando di dire. Se invece riuscirà a dare un senso alla frase inviata allora compirà l'azione corrispondente definita nello script python chiamato action.py, precedentemente definito durante la spiegazione di rasa core.

== TODO ==

<ol>

<li> Il problema principale è l'invio del jsession a Rasa. Per eseguire un pagamento completo è necessario che il bot possegga i cookies per poi incorporarli nella chiamata effettiva del pagamento. L'architettura base nel bot esiste già quindi non è un problema backend rasa, ma è del frontend che non può inviare il jsession dell'utente. Nel mio prototipo standalone inviavo questo dato a mano usando una chiamata rest. Questo è un problema differente dal xsrfToken infatti è possibile vedere come all'interno del chatbotUtilityService.js c'è una funzione chiamata enstablishConnectionWithRasa che manda questo dato senza problemi. Il metodo completo dovrebbe essere di questo tipo:
<pre>
    function enstablishConnectionWithRasa(xsrfToken, jsession, id) {

      // invio del xsrfToken
      $http.post("http://192.168.11.24:5005/conversations/" + id + "/tracker/events?token=wabridev",
        [{"event": "slot",
        "name": "xsrftoken",
        "value": xsrfToken }
      ],
      {
        'withCredentials': false
      }).then(function(response) {
        console.log("token salvato correttamente", response);
      }, function() {
        console.log("token impossibile da salvare");
      });

      // invio della jsession
      $http.post("http://192.168.11.24:5005/conversations/" + id + "/tracker/events?token=wabridev",
        [{"event": "slot",
        "name": "jsession",
        "value": jsession }
      ],
      {
        'withCredentials': false
      }).then(function(response) {
        console.log("jsession salvato correttamente", response);
      }, function() {
        console.log("jsession impossibile da salvare");
      });
    }
</pre>
Questo non è possibile farlo dato che dal frontend non ho accesso diretto alla jsession (che io sappia). Spero di essere stato chiaro.</li>



<li>
Ho inserito la funzionalità di speechRecognition e SynthVoice ma non ho ancora testato che funzioni perchè non riesco a togliere il blocco al microfono del browser. La parte di codice che si occupa di questo è nel controller.
</li>


<li>
  Il bottone di accesso alla pagina chat è a sfondo bianco con testo bianco. Mi dispiace ma non ho avuto tempo di modificarlo.
</li>


<li>
  La pagina della chat è dei primi anno 90. Non c'è grafica. Mi dispiace ma ho sempre ritenuto questa cosa secondaria.
</li>

</ol>
